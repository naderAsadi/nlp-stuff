{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BiLSTM.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1TaLJkzJVePYn16MN7nQBL4jIuvmZYnzu","authorship_tag":"ABX9TyMm/doz8Z9T3tcE2zH9z+qb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"1WZgzL7zpZzO","colab_type":"text"},"source":["## Load Data"]},{"cell_type":"code","metadata":{"id":"3metjqZ5RWAR","colab_type":"code","outputId":"627aa8eb-e3b7-42b6-92b5-ba5790e14620","executionInfo":{"status":"ok","timestamp":1584353320971,"user_tz":-210,"elapsed":29787,"user":{"displayName":"Nader Asadi","photoUrl":"","userId":"13987168146830248957"}},"colab":{"base_uri":"https://localhost:8080/","height":215}},"source":["!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","!tar xfz ./aclImdb_v1.tar.gz"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2020-03-16 10:08:13--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n","Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 84125825 (80M) [application/x-gzip]\n","Saving to: ‘aclImdb_v1.tar.gz’\n","\n","aclImdb_v1.tar.gz   100%[===================>]  80.23M  16.0MB/s    in 8.3s    \n","\n","2020-03-16 10:08:27 (9.64 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iYwX89L9kghG","colab_type":"code","colab":{}},"source":["import os\n","import numpy as np\n","\n","def get_files(dir):\n","  return [dir + d for d in os.listdir(dir) if os.path.isfile(dir + d)]\n","\n","train_dir = '/content/aclImdb/train/'\n","test_dir = '/content/aclImdb/test/'\n","\n","train_pos_files = get_files(train_dir + 'pos/')\n","train_neg_files = get_files(train_dir + 'neg/')\n","\n","test_pos_files = get_files(test_dir + 'pos/')\n","test_neg_files = get_files(test_dir + 'neg/')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oRhPXpcxlMik","colab_type":"code","colab":{}},"source":["def get_data(files):\n","  temp = []\n","  for c in files:\n","    with open(c, 'r') as f:\n","      temp.append(f.read())\n","  return temp\n","\n","train_pos = get_data(train_pos_files)\n","train_neg = get_data(train_neg_files)\n","\n","test_pos = get_data(test_pos_files)\n","test_neg = get_data(test_neg_files)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cokkrRRrpewH","colab_type":"text"},"source":["## Data Processing"]},{"cell_type":"markdown","metadata":{"id":"951K5uxot0Bm","colab_type":"text"},"source":["<ul>\n","  <li><b>Convert to lower case</b>\n","  <li><b>Remove Punctuation</b>\n","</ul>"]},{"cell_type":"code","metadata":{"id":"loR8bAF3lMnk","colab_type":"code","colab":{}},"source":["from string import punctuation\n","\n","def preprocess(data):\n","  for i in range(len(data)):\n","    s = data[i]\n","    s = s.replace('<br />', '')\n","    data[i] = ''.join([c for c in s.lower() if c not in punctuation])\n","\n","  return data\n","\n","train_pos = preprocess(train_pos)\n","train_neg = preprocess(train_neg)\n","test_pos = preprocess(test_pos)\n","test_neg = preprocess(test_neg)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9tVyUPaXvAYf","colab_type":"text"},"source":["## Tokenize\n","\n","<li><b>Create word to index mapping dictionary</b>\n","\n","There is a small trick here, in this mapping index will start from 0 i.e. mapping of ‘the’ will be 0. But later on we are going to do padding for shorter reviews and conventional choice for padding is 0. So we need to start this indexing from 1"]},{"cell_type":"code","metadata":{"id":"DAhTTg88p1uz","colab_type":"code","colab":{}},"source":["from collections import Counter\n","\n","words = ' '.join(train_pos + train_neg + test_pos + test_neg)\n","words = words.split()\n","\n","count_words = Counter(words)\n","total = len(words)\n","sorted_words = count_words.most_common(total)\n","\n","word2idx = {w:i+1 for i,(w,c) in enumerate(sorted_words)}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kXsXEoVuzEyb","colab_type":"text"},"source":["<li><b>Encode the words"]},{"cell_type":"code","metadata":{"id":"TFhnJDmhxoic","colab_type":"code","colab":{}},"source":["def encode_words(data):\n","  data_idx = []\n","  for review in data:\n","    data_idx.append([word2idx[w] for w in review.split()])\n","  return data_idx\n","\n","train_pos_idx = encode_words(train_pos)\n","train_neg_idx = encode_words(train_neg)\n","test_pos_idx = encode_words(test_pos)\n","test_neg_idx = encode_words(test_neg)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dmZoOBJVe1ul","colab_type":"code","colab":{}},"source":["train_pos_labels = np.full(len(train_pos_idx), 1).tolist()\n","train_neg_labels = np.full(len(train_neg_idx), 0).tolist()\n","test_pos_labels = np.full(len(test_pos_idx), 1).tolist()\n","test_neg_labels = np.full(len(test_neg_idx), 0).tolist()\n","\n","train_labels = train_pos_labels + train_neg_labels\n","test_labels = np.array(test_pos_labels + test_neg_labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uZvnMcCwZutE","colab_type":"code","colab":{}},"source":["train_reviews = train_pos + train_neg\n","train_reviews_idx = train_pos_idx + train_neg_idx\n","test_reviews_idx = test_pos_idx + test_neg_idx"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"USFjTc_ctjKN","colab_type":"code","colab":{}},"source":["train_reviews_idx = train_reviews_idx[:11250] + train_reviews_idx[13750:]\n","val_reviews_idx = train_reviews_idx[11250:13750]\n","\n","train_labels = np.array(train_labels[:11250] + train_labels[13750:])\n","val_labels = np.array(train_labels[11250:13750])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Fem4Q7r4QW6","colab_type":"text"},"source":["## Analyze Reviews Length"]},{"cell_type":"code","metadata":{"id":"-_Slq90C4Tvv","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XY4dhard4U2R","colab_type":"code","outputId":"8a58cacd-2143-4b39-c39c-1a579d4d4da9","executionInfo":{"status":"ok","timestamp":1584353333507,"user_tz":-210,"elapsed":36154,"user":{"displayName":"Nader Asadi","photoUrl":"","userId":"13987168146830248957"}},"colab":{"base_uri":"https://localhost:8080/","height":427}},"source":["reviews_len = [len(x) for x in train_reviews]\n","pd.Series(reviews_len).hist()\n","plt.show()\n","\n","pd.Series(reviews_len).describe()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["count    25000.000000\n","mean      1259.745280\n","std        954.738337\n","min         51.000000\n","25%        670.000000\n","50%        931.000000\n","75%       1532.000000\n","max      13286.000000\n","dtype: float64"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"1-G_Y2SvbdhZ","colab_type":"text"},"source":["<li><b>Padding / Truncating the remaining data"]},{"cell_type":"code","metadata":{"id":"4JV8p5uQ4Uz3","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def pad_features(reviews, seq_length):\n","    ''' \n","      Return features of review_ints, where each review is padded with 0's or truncated to the input seq_length.\n","    '''\n","    features = np.zeros((len(reviews), seq_length), dtype = int)\n","    \n","    for i, review in enumerate(reviews):\n","        review_len = len(review)\n","        \n","        if review_len <= seq_length:\n","            zeroes = list(np.zeros(seq_length-review_len))\n","            new = zeroes+review\n","        elif review_len > seq_length:\n","            new = review[0:seq_length]\n","        \n","        features[i,:] = np.array(new)\n","    \n","    return features"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZDYf4ZsEbb6y","colab_type":"code","colab":{}},"source":["seq_length = 200\n","train_features = pad_features(train_reviews_idx, seq_length)\n","val_features = pad_features(val_reviews_idx, seq_length)\n","test_features = pad_features(test_reviews_idx, seq_length)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hU1F94tI_H0d","colab_type":"text"},"source":["## Dataloaders and Batching"]},{"cell_type":"code","metadata":{"id":"R5UpeMsO-_EE","colab_type":"code","colab":{}},"source":["import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","# create Tensor datasets\n","train_data = TensorDataset(torch.from_numpy(train_features), torch.from_numpy(train_labels))\n","val_data = TensorDataset(torch.from_numpy(val_features), torch.from_numpy(val_labels))\n","test_data = TensorDataset(torch.from_numpy(test_features), torch.from_numpy(test_labels))\n","\n","# dataloaders\n","batch_size = 50\n","\n","# make sure to SHUFFLE your data\n","train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n","val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size)\n","test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KphaCqEP-_Gf","colab_type":"code","outputId":"65fa798e-c0b9-4565-f399-6fc661693d2c","executionInfo":{"status":"ok","timestamp":1584353334047,"user_tz":-210,"elapsed":30005,"user":{"displayName":"Nader Asadi","photoUrl":"","userId":"13987168146830248957"}},"colab":{"base_uri":"https://localhost:8080/","height":287}},"source":["# obtain one batch of training data\n","dataiter = iter(train_loader)\n","sample_x, sample_y = dataiter.next()\n","print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n","print('Sample input: \\n', sample_x)\n","print()\n","print('Sample label size: ', sample_y.size()) # batch_size\n","print('Sample label: \\n', sample_y)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sample input size:  torch.Size([50, 200])\n","Sample input: \n"," tensor([[   8,    6,  323,  ...,  194, 3333,    2],\n","        [   0,    0,    0,  ..., 2514,  411, 3115],\n","        [   0,    0,    0,  ...,    5,  859, 1090],\n","        ...,\n","        [   7,   10,   18,  ...,   61,  602, 3834],\n","        [   0,    0,    0,  ...,  354,   10,  969],\n","        [   0,    0,    0,  ..., 5849,  784,  646]])\n","\n","Sample label size:  torch.Size([50])\n","Sample label: \n"," tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n","        0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n","        0, 1])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iSLnFMWb_tg4","colab_type":"text"},"source":["## LSTM Model"]},{"cell_type":"markdown","metadata":{"id":"qO6eKjzn0REU","colab_type":"text"},"source":["<b>LSTM in Pytorch:</b><br>\n","Inputs: input, (h_0, c_0)<br>\n","Outputs: output, (h_n, c_n)<br>\n","<p>* This is the reason we create a tuple of two parameters for hidden state.</p>\n","<p>* For BiLSTM we should multiply number of hidden layers by two.</p>\n","<a href='https://discuss.pytorch.org/t/bidirectional-lstm-implementation/4037'> Pytorch Forum<a/>"]},{"cell_type":"code","metadata":{"id":"r71vEYeB-_JC","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","\n","class SentimentBiLSTM(nn.Module):\n","  def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n","    super(SentimentBiLSTM, self).__init__()\n","\n","    self.output_size = output_size\n","    self.n_layers = n_layers\n","    self.hidden_dim = hidden_dim\n","\n","    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","    self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True, bidirectional=True)\n","\n","    self.dropout = nn.Dropout(0.3)\n","\n","    self.fc = nn.Linear(hidden_dim, output_size)\n","    self.sig = nn.Sigmoid()\n","\n","  def forward(self, x, hidden):\n","    batch_size = x.size(0)\n","    embeds =self.embedding(x)\n","    lstm_out, hidden = self.lstm(embeds, hidden)\n","\n","    # stack up lstm outputs\n","    lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n","\n","    out = self.dropout(lstm_out)\n","    out = self.fc(out)\n","    # sigmoid function\n","    sig_out = self.sig(out)\n","        \n","    # reshape to be batch_size first\n","    sig_out = sig_out.view(batch_size, -1)\n","    sig_out = sig_out[:, -1] # get last batch of labels\n","        \n","    # return last sigmoid output and hidden state\n","    return sig_out, hidden\n","\n","  def init_hidden(self, batch_size):\n","    ''' Initializes hidden state '''\n","    # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n","    # initialized to zero, for hidden state and cell state of LSTM\n","    weight = next(self.parameters()).data\n","      \n","    if (train_on_gpu):\n","        hidden = (weight.new(self.n_layers * 2, batch_size, self.hidden_dim).zero_().cuda(),\n","                weight.new(self.n_layers * 2, batch_size, self.hidden_dim).zero_().cuda())\n","    else:\n","        hidden = (weight.new(self.n_layers * 2, batch_size, self.hidden_dim).zero_(),\n","                weight.new(self.n_layers * 2, batch_size, self.hidden_dim).zero_())\n","        \n","    return hidden\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"we6iwYEdCS8U","colab_type":"text"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"_IsS9rcxArmF","colab_type":"code","colab":{}},"source":["# Instantiate the model w/ hyperparams\n","vocab_size = len(word2idx) + 1 # +1 for the 0 padding\n","output_size = 1\n","embedding_dim = 400\n","hidden_dim = 256\n","n_layers = 2\n","train_on_gpu = True\n","\n","net = SentimentBiLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1tjLrGYiArom","colab_type":"code","colab":{}},"source":["lr=0.001\n","epochs = 4\n","counter = 0\n","print_every = 100\n","clip=5 # gradient clipping\n","\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n","\n","if(train_on_gpu):\n","    net.cuda()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hd8tMLBJ-_CD","colab_type":"code","outputId":"d1ed6a2d-f810-4283-b523-fcd54cc20020","executionInfo":{"status":"ok","timestamp":1584354186337,"user_tz":-210,"elapsed":372430,"user":{"displayName":"Nader Asadi","photoUrl":"","userId":"13987168146830248957"}},"colab":{"base_uri":"https://localhost:8080/","height":341}},"source":["net.train()\n","# train for some number of epochs\n","for e in range(epochs):\n","    # initialize hidden state\n","    h = net.init_hidden(batch_size)\n","\n","    # batch loop\n","    for inputs, labels in train_loader:\n","        counter += 1\n","\n","        if(train_on_gpu):\n","            inputs, labels = inputs.cuda(), labels.cuda()\n","\n","        # Creating new variables for the hidden state, otherwise\n","        # we'd backprop through the entire training history\n","        h = tuple([each.data for each in h])\n","\n","        # zero accumulated gradients\n","        net.zero_grad()\n","\n","        # get the output from the model\n","        inputs = inputs.type(torch.LongTensor).cuda()\n","        output, h = net(inputs, h)\n","\n","        # calculate the loss and perform backprop\n","        loss = criterion(output.squeeze(), labels.float())\n","        loss.backward()\n","        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n","        nn.utils.clip_grad_norm_(net.parameters(), clip)\n","        optimizer.step()\n","\n","        # loss stats\n","        if counter % print_every == 0:\n","            # Get validation loss\n","            val_h = net.init_hidden(batch_size)\n","            val_losses = []\n","            net.eval()\n","            for inputs, labels in val_loader:\n","\n","                # Creating new variables for the hidden state, otherwise\n","                # we'd backprop through the entire training history\n","                val_h = tuple([each.data for each in val_h])\n","\n","                if(train_on_gpu):\n","                    inputs, labels = inputs.cuda(), labels.cuda()\n","\n","                inputs = inputs.type(torch.LongTensor).cuda()\n","                output, val_h = net(inputs, val_h)\n","                val_loss = criterion(output.squeeze(), labels.float())\n","\n","                val_losses.append(val_loss.item())\n","\n","            net.train()\n","            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n","                  \"Step: {}...\".format(counter),\n","                  \"Loss: {:.6f}...\".format(loss.item()),\n","                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 1/4... Step: 100... Loss: 0.652669... Val Loss: 0.620840\n","Epoch: 1/4... Step: 200... Loss: 0.702466... Val Loss: 0.658140\n","Epoch: 1/4... Step: 300... Loss: 0.693225... Val Loss: 0.680569\n","Epoch: 1/4... Step: 400... Loss: 0.663828... Val Loss: 0.517838\n","Epoch: 2/4... Step: 500... Loss: 0.531397... Val Loss: 0.454757\n","Epoch: 2/4... Step: 600... Loss: 0.524250... Val Loss: 0.198840\n","Epoch: 2/4... Step: 700... Loss: 0.743830... Val Loss: 0.491184\n","Epoch: 2/4... Step: 800... Loss: 0.590345... Val Loss: 0.234661\n","Epoch: 2/4... Step: 900... Loss: 0.376590... Val Loss: 0.296031\n","Epoch: 3/4... Step: 1000... Loss: 0.303097... Val Loss: 0.621736\n","Epoch: 3/4... Step: 1100... Loss: 0.231349... Val Loss: 0.238768\n","Epoch: 3/4... Step: 1200... Loss: 0.303078... Val Loss: 0.160401\n","Epoch: 3/4... Step: 1300... Loss: 0.299275... Val Loss: 0.225852\n","Epoch: 4/4... Step: 1400... Loss: 0.200305... Val Loss: 0.065180\n","Epoch: 4/4... Step: 1500... Loss: 0.398797... Val Loss: 0.133489\n","Epoch: 4/4... Step: 1600... Loss: 0.190258... Val Loss: 0.158537\n","Epoch: 4/4... Step: 1700... Loss: 0.391834... Val Loss: 0.302014\n","Epoch: 4/4... Step: 1800... Loss: 0.413490... Val Loss: 0.111988\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"a0FS3kOTFNDT","colab_type":"text"},"source":["## Testing"]},{"cell_type":"code","metadata":{"id":"duhT4dYzDQeD","colab_type":"code","outputId":"0079ea93-a157-4f83-960b-baa1d63be742","executionInfo":{"status":"ok","timestamp":1584354216329,"user_tz":-210,"elapsed":19132,"user":{"displayName":"Nader Asadi","photoUrl":"","userId":"13987168146830248957"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["# Get test data loss and accuracy\n","test_losses = [] # track loss\n","num_correct = 0\n","\n","# init hidden state\n","h = net.init_hidden(batch_size)\n","\n","net.eval()\n","# iterate over test data\n","for inputs, labels in test_loader:\n","\n","    # Creating new variables for the hidden state, otherwise\n","    # we'd backprop through the entire training history\n","    h = tuple([each.data for each in h])\n","\n","    if(train_on_gpu):\n","        inputs, labels = inputs.cuda(), labels.cuda()\n","    \n","    # get predicted outputs\n","    inputs = inputs.type(torch.LongTensor).cuda()\n","    output, h = net(inputs, h)\n","    \n","    # calculate loss\n","    test_loss = criterion(output.squeeze(), labels.float())\n","    test_losses.append(test_loss.item())\n","    \n","    # convert output probabilities to predicted class (0 or 1)\n","    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n","    \n","    # compare predictions to true label\n","    correct_tensor = pred.eq(labels.float().view_as(pred))\n","    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n","    num_correct += np.sum(correct)\n","\n","\n","# -- stats! -- ##\n","# avg test loss\n","print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n","\n","# accuracy over all test data\n","test_acc = num_correct/len(test_loader.dataset)\n","print(\"Test accuracy: {:.3f}\".format(test_acc))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test loss: 0.471\n","Test accuracy: 0.818\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8XujmfM0FSlN","colab_type":"text"},"source":["## On user-generated data"]},{"cell_type":"code","metadata":{"id":"epyz3qWCFVp2","colab_type":"code","colab":{}},"source":["from string import punctuation\n","\n","def tokenize_review(test_review):\n","    test_review = test_review.lower() # lowercase\n","    # get rid of punctuation\n","    test_text = ''.join([c for c in test_review if c not in punctuation])\n","\n","    # splitting by spaces\n","    test_words = test_text.split()\n","\n","    # tokens\n","    test_ints = []\n","    test_ints.append([vocab_to_int[word] for word in test_words])\n","\n","    return test_ints\n","\n","# test code and generate tokenized review\n","test_ints = tokenize_review(test_review_neg)\n","print(test_ints)\n","\n","\n","# test sequence padding\n","seq_length=200\n","features = pad_features(test_ints, seq_length)\n","\n","print(features)\n","\n","\n","# test conversion to tensor and pass into your model\n","feature_tensor = torch.from_numpy(features)\n","print(feature_tensor.size())\n","\n","\n","def predict(net, test_review, sequence_length=200):\n","    \n","    net.eval()\n","    \n","    # tokenize review\n","    test_ints = tokenize_review(test_review)\n","    \n","    # pad tokenized sequence\n","    seq_length=sequence_length\n","    features = pad_features(test_ints, seq_length)\n","    \n","    # convert to tensor to pass into your model\n","    feature_tensor = torch.from_numpy(features)\n","    \n","    batch_size = feature_tensor.size(0)\n","    \n","    # initialize hidden state\n","    h = net.init_hidden(batch_size)\n","    \n","    if(train_on_gpu):\n","        feature_tensor = feature_tensor.cuda()\n","    \n","    # get the output from the model\n","    output, h = net(feature_tensor, h)\n","    \n","    # convert output probabilities to predicted class (0 or 1)\n","    pred = torch.round(output.squeeze()) \n","    # printing output value, before rounding\n","    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n","    \n","    # print custom response\n","    if(pred.item()==1):\n","        print(\"Positive review detected!\")\n","    else:\n","        print(\"Negative review detected.\")"],"execution_count":0,"outputs":[]}]}