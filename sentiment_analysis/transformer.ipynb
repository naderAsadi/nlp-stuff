{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transformer.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNcSXuq7KA2Pj48qFa02FQ2"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"HyDTixXB-MY_","colab_type":"code","colab":{}},"source":["import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import TransformerEncoder, TransformerEncoderLayer\n","import torchtext"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UcCEACkD_pEJ","colab_type":"text"},"source":["## Data"]},{"cell_type":"code","metadata":{"id":"1Z6h18vM-XlM","colab_type":"code","colab":{}},"source":["TEXT = torchtext.data.Field(tokenize='spacy',\n","                            init_token='<sos>',\n","                            eos_token='<eos>',\n","                            lower=True)\n","LABEL = torchtext.data.LabelField(dtype=torch.float)\n","\n","train_txt, test_txt = torchtext.datasets.IMDB.splits(TEXT, LABEL)\n","\n","TEXT.build_vocab(train_txt)\n","LABEL.build_vocab(train_txt)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3dYI_RIo-XnJ","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 32\n","\n","train_iterator, test_iterator = torchtext.data.BucketIterator.splits(\n","    (train_txt, test_txt),\n","    batch_size = BATCH_SIZE,\n","    device = device\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zOJKog96_qj2","colab_type":"text"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"pjqikYyX-Xp3","colab_type":"code","colab":{}},"source":["class Transformer(nn.Module):\n","\n","  def __init__(self, num_token, embed_size, num_head, len_ff, output_size, num_layers, dropout=0.5):\n","    super(Transformer, self).__init__()\n","    self.model_type = 'Transformer'\n","    self.src_mask = None\n","    self.pos_encoder = PositionalEncoding(embed_size, dropout)\n","    encoder_layers = TransformerEncoderLayer(embed_size, num_head, len_ff, dropout)\n","    self.trans_encoder = TransformerEncoder(encoder_layers, num_layers)\n","    self.embed = nn.Embedding(num_token, embed_size)\n","    self.embed_size = embed_size\n","    self.decoder = nn.Linear(embed_size, output_size)\n","    self.sig = nn.Sigmoid()\n","\n","    self.init_weights()\n","\n","  def _generate_square_subsequent_mask(self, size):\n","    mask = (torch.triu(torch.ones(size, size)) == 1).transpose(0, 1)\n","    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","    return mask\n","\n","  def init_weights(self):\n","    initrange = 0.1\n","    self.embed.weight.data.uniform_(-initrange, initrange)\n","    self.decoder.bias.data.zero_()\n","    self.decoder.weight.data.uniform_(-initrange, initrange)\n","\n","  def forward(self, src):\n","    if self.src_mask is None or self.src_mask.size(0) != len(src):\n","        device = src.device\n","        mask = self._generate_square_subsequent_mask(len(src)).to(device)\n","        self.src_mask = mask\n","\n","    src = self.embed(src) * math.sqrt(self.embed_size)\n","    src = self.pos_encoder(src)\n","    output = self.trans_encoder(src, self.src_mask)\n","    output = output.sum(dim=0).float()\n","    output = self.decoder(output)\n","    output = self.sig(output)\n","    return output.squeeze()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HRqbLk6U-XsU","colab_type":"code","colab":{}},"source":["class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:x.size(0), :]\n","        return self.dropout(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ST85mWn-Xu9","colab_type":"code","colab":{}},"source":["ntokens = len(TEXT.vocab.stoi) # the size of vocabulary\n","emsize = 200 # embedding dimension\n","nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n","nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n","nhead = 2 # the number of heads in the multiheadattention models\n","out_size = 1\n","dropout = 0.2 # the dropout value\n","model = Transformer(ntokens, emsize, nhead, nhid, out_size, nlayers, dropout).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_mRVlFuvDfsQ","colab_type":"text"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"Nl2cim1ACxy7","colab_type":"code","colab":{}},"source":["criterion = nn.BCELoss()\n","lr = 5.0 # learning rate\n","optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gnjh9ePPCx1T","colab_type":"code","colab":{}},"source":["import time\n","def train():\n","    model.train() # Turn on the train mode\n","    total_loss = 0.\n","    start_time = time.time()\n","    ntokens = len(TEXT.vocab.stoi)\n","    i = 0\n","    for batch in train_iterator:\n","        data, targets = batch.text, batch.label\n","        optimizer.zero_grad()\n","        output = model(data)\n","        print(data.shape, targets.shape)\n","        #loss = criterion(output.view(-1, ntokens), targets)\n","        loss = criterion(output, targets)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        log_interval = 200\n","        if i % log_interval == 0 and i > 0:\n","            cur_loss = total_loss / log_interval\n","            elapsed = time.time() - start_time\n","            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n","                  'lr {:02.2f} | ms/batch {:5.2f} | '\n","                  'loss {:5.2f} | ppl {:8.2f}'.format(\n","                    epoch, i, len(train_data) // bptt, scheduler.get_lr()[0],\n","                    elapsed * 1000 / log_interval,\n","                    cur_loss, math.exp(cur_loss)))\n","            total_loss = 0\n","            i += 32\n","            start_time = time.time()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-FYPiF-nCx32","colab_type":"code","colab":{}},"source":["def test(test_model, iterator):\n","    test_model.eval() # Turn on the evaluation mode\n","    total_loss = 0.\n","    ntokens = len(TEXT.vocab.stoi)\n","    with torch.no_grad():\n","        for batch in iterator:\n","            data, targets = batch.data, batch.label\n","            output = test_model(data)\n","            #output_flat = output.view(-1, ntokens)\n","            total_loss += criterion(output, targets).item()\n","    return total_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"giSGdAx7Cx6P","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":359},"outputId":"d51fa541-ea08-4bab-b6d6-4204b6614e55"},"source":["best_val_loss = float(\"inf\")\n","epochs = 3 # The number of epochs\n","best_model = None\n","\n","for epoch in range(1, epochs + 1):\n","    epoch_start_time = time.time()\n","    train()\n","\n","    #val_loss = evaluate(model, val_data)\n","    #print('-' * 89)\n","    #print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n","    #      'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n","    #                                 val_loss, math.exp(val_loss)))\n","    #print('-' * 89)\n","\n","    #if val_loss < best_val_loss:\n","    #    best_val_loss = val_loss\n","    #    best_model = model\n","\n","    scheduler.step()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([1389, 32]) torch.Size([32])\n","torch.Size([452, 32]) torch.Size([32])\n","torch.Size([694, 32]) torch.Size([32])\n","torch.Size([1084, 32]) torch.Size([32])\n","torch.Size([870, 32]) torch.Size([32])\n","torch.Size([1121, 32]) torch.Size([32])\n","torch.Size([938, 32]) torch.Size([32])\n","torch.Size([1152, 32]) torch.Size([32])\n","torch.Size([908, 32]) torch.Size([32])\n","torch.Size([1165, 32]) torch.Size([32])\n","torch.Size([888, 32]) torch.Size([32])\n","torch.Size([1248, 32]) torch.Size([32])\n","torch.Size([1162, 32]) torch.Size([32])\n","torch.Size([952, 32]) torch.Size([32])\n","torch.Size([1145, 32]) torch.Size([32])\n","torch.Size([817, 32]) torch.Size([32])\n","torch.Size([1036, 32]) torch.Size([32])\n","torch.Size([827, 32]) torch.Size([32])\n","torch.Size([1014, 32]) torch.Size([32])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eokuZF-pCx8w","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y8MUXCxJCx_Q","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}